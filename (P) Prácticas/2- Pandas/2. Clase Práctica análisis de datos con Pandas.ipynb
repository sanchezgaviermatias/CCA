{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71b0ebe",
   "metadata": {},
   "source": [
    "## 2. Clase práctica - Análisis de datos con Pandas - Parte 1\n",
    "\n",
    "## Para realizar esta NB deben tener los datasets data1 y data2 en formato csv.\n",
    "\n",
    "**Importamos librerias que vamos a usar en toda la NB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beabc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca4e2b2",
   "metadata": {},
   "source": [
    "### Importar los dataframes.\n",
    "\n",
    "**Llamar al data1.csv \"df\" y al data2 \"df_variables\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da67acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e451a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98c4a4a2",
   "metadata": {},
   "source": [
    "### Detalles de la data:\n",
    "\n",
    "**Es importante destacar que no importa mucho que significa cada variable en esta NB, ya que el objetivo principal es que puedan realizar los ejercicios y entender cómo funciona pandas**.\n",
    "\n",
    "No obstante, les dejamos una breve descripción de algunos atributos en caso que lo necesiten.\n",
    "\n",
    "- rut = ID de cada observación.\n",
    "- Periodo = periodo de cada observación.\n",
    "- Los campos rut y periodo son las claves por las cuales los registros son únicos, es decir que no hay duplicados con mismo rut y periodo.\n",
    "- ind_activo: Informacion si el cliente se encuentre activo.\n",
    "- estado_solicitud: estado en el que se encuentra la solcitud del cliente.\n",
    "- captacion: metodo de captacion por el cual fue captado el cliente.\n",
    "- marca_6m_60d_final: 1 si el cliente es malo y 0 si es bueno.\n",
    "- etc.\n",
    "\n",
    "#### Si importaron el dataset y les quedo la columna \"Unnamed: 0\". Eliminarla usando drop\n",
    "\n",
    "**Atentos a no olvidarse el inplace=True!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddf0b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ed2b432",
   "metadata": {},
   "source": [
    "### 1) Realizar Sanity check de la data.\n",
    "\n",
    "Para este primer punto, utilizar el dataset df que hace referencia al **data1.csv.** No obstante, si quieren realizarlo en ambos, nunca esta demás.\n",
    "\n",
    "**Funciones Útiles**\n",
    "\n",
    "* .head()\n",
    "* .info()\n",
    "* .shape\n",
    "* .dtypes\n",
    "* .describe\n",
    "* .isna()\n",
    "* .sum()\n",
    "* .unique()\n",
    "* .nunique()\n",
    "* .value_counts()\n",
    "\n",
    "#### 1.1) Observar las primeras 5 filas del dataset \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7ed87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437b989b",
   "metadata": {},
   "source": [
    "#### 1.2) Observar las últimas 5 filas del dataset \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ff087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80f34f3",
   "metadata": {},
   "source": [
    "#### 1.3) Obtener información general del dataframe utilizando .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6f02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "095848cb",
   "metadata": {},
   "source": [
    "#### 1.4) Obtener dimensiones del dataframe (filas y columnas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6fcea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff470f27",
   "metadata": {},
   "source": [
    "#### 1.5) Obtener tipo de datos de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5537ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fd192cd",
   "metadata": {},
   "source": [
    "#### 1.6) Seleccionar las columnas ind_activo, estado_solicitud y cant_tel y realizar un .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fddc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b8f34c",
   "metadata": {},
   "source": [
    "#### 1.7) Observar la distribucion de estas 3 variables utilizando el método describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6375853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1349ee7",
   "metadata": {},
   "source": [
    "#### 1.8) Chequear cantidad de valores nulos por columna.\n",
    "\n",
    "**Pista:** Utilizar isna() y luego la suma de ello para obtener los valores por columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9963d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b3c114",
   "metadata": {},
   "source": [
    "#### 1.9) Calcular el valor de nulos en %.\n",
    "\n",
    "**Pista:** Dividir el bloque de codigo anterior por la cantidad de filas en el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213391a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb98fb89",
   "metadata": {},
   "source": [
    "#### 1.9) Obtener la cantidad de valores únicos en las columnas categoricas.\n",
    "\n",
    "- Primero seleccionar las columnas categoricas\n",
    "- Luego correr nunique() en cada una **Fijarse de agregar el parametro dropna=False para tener en cuenta nulos**\n",
    "- Luego si quieren con unique() pueden ver cuales son aquellos valores únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0fdb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "769ec86e",
   "metadata": {},
   "source": [
    "#### 1.10) Calcular la distirbución por la variable captacion (cuantos registros hay por cada valor unico de captacion).\n",
    "\n",
    "Utilizar la funcion value_counts() y tener en cuenta dropna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a53c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbc186f0",
   "metadata": {},
   "source": [
    "Si lo queremos ver en %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe146c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7a7813c",
   "metadata": {},
   "source": [
    "### 2) Tratamiento de Datos\n",
    "\n",
    "#### 2.1) Imputacion de nulos \n",
    "\n",
    "Para esta parte vamos a usar el dataset \"df_variables\" que hace referencia al data2.csv\n",
    "\n",
    "#### Imputar las columnas predictor1_7 y predictor1_9 por el valor 100. \n",
    "\n",
    "Primero chequear que tengan nulos.\n",
    "\n",
    "**Pista:** Utilizar fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1de11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189617f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50e96e9c",
   "metadata": {},
   "source": [
    "#### Imputar las columnas predictor1_10 y predictor1_11 por la media de cada columna.\n",
    "\n",
    "Primero chequear que tengan nulos.\n",
    "\n",
    "**Pista:** Utilizar fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b80943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d580f07e",
   "metadata": {},
   "source": [
    "#### 2.2) Tratamiento strings: upper, lower, replace\n",
    "\n",
    "Para esta parte vamos a usar el dataset \"df\" que hace referencia al **data1.csv**\n",
    "\n",
    "Muchas veces hay que realizar cambios en variables que vienen como string, por ejemplo, llevar todo a mayúsculas, minúsculas, reemplazar un simbolo, dividir por algún valor (*split*), etc. Pandas trae incorporada distintas funciones que nos ayudan a cumplir estas tareas. La forma de acceder a estas funciones es la siguiente:\n",
    "\n",
    "``` pd.Series.str.#funcion```\n",
    "\n",
    "``` tu_df.tu_columna.str.upper()```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a618fd",
   "metadata": {},
   "source": [
    "#### Convertir los valores de captacion a letra miniscula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fc37e",
   "metadata": {},
   "source": [
    "Se puede hacer con str.lower() o con una funcion lambda x luego de aplicar un apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982127b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae2fec6f",
   "metadata": {},
   "source": [
    "#### Convertir los valores de vuelta a mayusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0967b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3d999e0",
   "metadata": {},
   "source": [
    "####  Ahora, si reemplazar algún simbolo por podemos usar la funcion ```str.replace```, la cual toma un substring y lo convierte en otro.\n",
    "Por ejemplo, reemplazar todas las \"ex\" por otro string en la columna ```captacion```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef9b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd14517a",
   "metadata": {},
   "source": [
    "#### 2.3) Tratamiento de duplicados .   \n",
    "\n",
    "**Tener en cuenta que este tema no se dio en la NB teórica pero los ejercicios pueden ser realizados si investigan un poco. No obstante, no se preocupen si no los pueden realizar ya que serán explicados en la clase práctica tambien.**\n",
    "\n",
    "Seguimos utilizando el **data1 (df).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae2088",
   "metadata": {},
   "source": [
    "#### Chequear cantidad de duplicados de las columnas estado_solicitud y periodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8795e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8f5aa8d",
   "metadata": {},
   "source": [
    "#### Chequear si tenemos duplicados por rut y periodo. Utilizar subset como parametro en la funcion duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617f496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "444604f1",
   "metadata": {},
   "source": [
    "**En la clase practica veremos como dropear duplicados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a583240c",
   "metadata": {},
   "source": [
    "#### 2.4) Seleccion de distintas variables y filas.\n",
    "\n",
    "Utilizar el dataset df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97094f0d",
   "metadata": {},
   "source": [
    "#### Seleccionar las columnas rut, periodo y captacion, en donde captacion sea EXPRESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43aebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ccf1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbde3468",
   "metadata": {},
   "source": [
    "#### Seleccionar filas donde captacion es EXPRESS y estado solicitud Aprobado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f06df9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64f1747",
   "metadata": {},
   "source": [
    "#### Seleccionar filas donde captacion es NORMAL, estado solicitud es Aprobado y el ind_activo es = 1. Sólo seleccionar las columnas rut, periodo, cant tel y ordenar de mayor a menor por cant_tel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7ce42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d87d53",
   "metadata": {},
   "source": [
    "### 3) Joineo de tablas\n",
    "\n",
    "#### MERGE\n",
    "\n",
    "**3.1) Joineemos los dos dataframes que tenemos, por las claves de fusion que serán rut y periodo.**\n",
    "\n",
    "Crear un dataset que se llame df_nuevo que sea un inner join entre df y df_variables. **Usar pd.merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d494935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "municipal-repository",
   "metadata": {
    "id": "municipal-repository"
   },
   "source": [
    "**3.1 bis)**\n",
    "Con el .head() podemos ver que el nuevo df contiene nuevas variables, las que agregamos desde df_variables. Vemos también que las variables que fueron clave de fusion no se duplicaron, lo cual es bueno. \n",
    "\n",
    "**Ahora ¿ Qué pasa si las claves de fusion se llaman distinto? Utilizar left_on y right_on**\n",
    "\n",
    "A pesar de que las variables se llaman, y el código debajo no haria falta en este caso, muchas veces se van a encontrar con distintos nombres de claves de fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-council",
   "metadata": {
    "id": "accurate-council",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d2acfc",
   "metadata": {},
   "source": [
    "**3.2) Realizar un left join pero sólo trayendo algunas variables del dataset df_variables:\n",
    "'predictor1_7', 'predictor1_8', 'predictor1_9', 'ignite_ise'** . El left join debe ser sobre el dataset df, es decir, que el left seria df y el right df_variables.\n",
    "\n",
    "Llamar a este dataframe df_merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea598368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d64176be",
   "metadata": {},
   "source": [
    "**Chequear shape del nuevo dataset para ver si se hizo correctamente o tenemos duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b44c65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "723254c7",
   "metadata": {},
   "source": [
    "### 4) Agrupación\n",
    "\n",
    "Para realizar agrupaciones, las 2 maneras más comunes son groupby y pivot_table. A pesar de que pivot_table no fue detallado en las NB de teoria, acá explicaremos un poco para que puedan realizar algunos ejercicios utilizando esta herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-occasions",
   "metadata": {
    "id": "unexpected-occasions"
   },
   "source": [
    "### Pivot table\n",
    "\n",
    "Pivot table es otra forma de realizar group by, la cuál es muy facil de entender si estamos acostumbrados a trabajar con tablas dinamicas en excel.\n",
    "\n",
    "**Código:**\n",
    "\n",
    "```pd.pivot_table(data, index='variable o variables indice', columns='variable o variables de columna', values='variable sobre la cual se va a calcular suma/cuenta/media/..., aggfunc='funciones de agregación que se van a apicar a cada variable')```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-antenna",
   "metadata": {
    "id": "outside-antenna"
   },
   "source": [
    "```pd.pivot_table(\n",
    "    data,\n",
    "    values=None,\n",
    "    index=None,\n",
    "    columns=None,\n",
    "    aggfunc='mean',\n",
    "    fill_value=None,\n",
    "    margins=False,\n",
    "    dropna=True,\n",
    "    margins_name='All',\n",
    "    observed=False,\n",
    ")```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-ireland",
   "metadata": {
    "id": "related-ireland"
   },
   "source": [
    "**Ejemplo - calcular la bad rate (mean de marca_60d_6m_final) por periodo y la cantidad de registros:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-external",
   "metadata": {
    "id": "suspected-external"
   },
   "source": [
    "Podemos ver que no usaremos parametro \"column\" ya que no hace falta, porque estamos agrupando por periodo y caluculando la media de marca malo (bad rate) y la cuenta de registros (0 y 1) por periodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-system",
   "metadata": {
    "id": "welcome-system",
    "outputId": "84276de0-e0f8-4f62-9a44-6302d01e6ddb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df_merge, index='periodo', values='marca_60d_6m_final', aggfunc=['mean', 'count', 'sum']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-effort",
   "metadata": {
    "id": "controversial-effort"
   },
   "source": [
    "**Ejemplo 1) - Queremos ver la cantidad de malos y buenos por periodo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-accommodation",
   "metadata": {
    "id": "global-accommodation",
    "outputId": "cceeae54-9461-4a0a-e0bd-a0217397bc6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df_merge, index='periodo', columns='marca_60d_6m_final', values='rut', aggfunc='count').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-reverse",
   "metadata": {
    "id": "major-reverse"
   },
   "source": [
    "Acá vemos que agregamos el parametro columna ya que queremos que cuente separando por marca malo (0 o 1). Como values pusimos rut ya que es una columna sin nulos que nos sirve para hacer el count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-metropolitan",
   "metadata": {
    "id": "romantic-metropolitan"
   },
   "source": [
    "**Ejemplo 2) - agrupar por periodo (indice), ver por captacion (columnas) sobre las columnas rut (count) y cant_tel (media).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-vitamin",
   "metadata": {
    "id": "electronic-vitamin",
    "outputId": "f111268c-aa06-4718-9d2b-4f9d1bbc9f0f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df_merge, index='periodo', columns='captacion', values=['rut', 'cant_tel'],\n",
    "              aggfunc={'rut':'count',\n",
    "                      'cant_tel':'mean'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-method",
   "metadata": {
    "id": "chief-method"
   },
   "source": [
    "Vemos que para mapear variable en values con la funcion, creamos un diccionario en aggfunc y elegimos que metrica calcularle a cada uno.\n",
    "\n",
    "**Otra forma de verlo es sin usar el parametro columna** - Esto va a ser más util para crear un nuevo dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-whole",
   "metadata": {
    "id": "yellow-whole",
    "outputId": "5002d3db-55ea-4583-a7b6-841f1a3db4f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df_merge, index=['periodo','captacion'], values=['rut', 'cant_tel'],\n",
    "              aggfunc={'rut':'count',\n",
    "                      'cant_tel':'mean'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-hierarchy",
   "metadata": {
    "id": "entitled-hierarchy"
   },
   "source": [
    "**La importancia de .reset_index()**\n",
    "\n",
    "Es muy importante destacar que si vamos a querer crear un dataset con la agrupacion realizada, es IMPRESCINDIBLE usar .reset_index() al final del codigo, ya que sino no quedara en el formato correcto.\n",
    "\n",
    "Miremos el ejemplo de arriba aplicando reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-connecticut",
   "metadata": {
    "id": "specific-connecticut",
    "outputId": "c59faa39-be4e-4467-ac00-2bec96582fcc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df_merge, index=['periodo','captacion'], values=['rut', 'cant_tel'],\n",
    "              aggfunc={'rut':'count',\n",
    "                      'cant_tel':'mean'}).reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-executive",
   "metadata": {
    "id": "abandoned-executive"
   },
   "source": [
    "**Ejercicio Práctico utilizando pivot_table**\n",
    "\n",
    "Agrupar por captacion y obtener la media y el desvio de cant_tel. Para esto crear un nuevo dataset que se llame: info_captacion.\n",
    "\n",
    "Una vez obtenido esto, joinear la nueva columna al df_merge con un left_join (clave de fusion='captacion'). \n",
    "\n",
    "Pista: Para esto una vez obtenido el df info_captacion, debemos renombrar las columnas de manera correcta.\n",
    "\n",
    "``` info_captacion.columns = ['captacion', 'mean_cant_tel', 'std_cant_tel'] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-barcelona",
   "metadata": {
    "id": "suspected-barcelona",
    "outputId": "6afdfa92-0457-4cec-f79d-fb2684d2ba95",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-cinema",
   "metadata": {
    "id": "intended-cinema",
    "outputId": "064e320a-1336-42d3-c793-d2a457e3dd5c",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "isolated-execution",
   "metadata": {
    "id": "isolated-execution"
   },
   "source": [
    "### Group by\n",
    "\n",
    "Group by es la forma más simple para agrupar variables. Es un poco más simple que pivot_table y las funciones son muy similares. **Muy importante recordar .reset_index() ya que cumple la misma funcion aquí**\n",
    "\n",
    "**Código**\n",
    "\n",
    "``` dataset.groupby(['variables de agrupacion'])['variables a calcular metrica'].agg(['métricas: count/mean/sum') ```\n",
    "\n",
    "Pueden ser mas de una variable de agrupacion, mas de una variable a calcular metrica y más de una metrica.\n",
    "\n",
    "**Ejemplo - Agrupar por captacion y calcular la media y la cantidad de registros utilizando la variable marca_60d_6m_final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb8a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge.groupby(['captacion'])['marca_60d_6m_final'].agg(['mean', 'count']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb723b7",
   "metadata": {},
   "source": [
    "**1) Ejercicio groupby simple**\n",
    "\n",
    "Agrupar por captacion y periodo, la bad rate (mean de marca_60d_6m_final). Convertir en dataframe en el formato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-julian",
   "metadata": {
    "id": "lyric-julian",
    "outputId": "05c60901-4c37-40b1-dcb2-ed03488aa84b",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6345e713",
   "metadata": {},
   "source": [
    "**2) Ejercicio groupby medio**\n",
    "\n",
    "Agrupar por captacion y periodo, la cantidad de registros (count del rut) y la bad rate (mean de marca_60d_6m_final)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf493e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mighty-spiritual",
   "metadata": {
    "id": "mighty-spiritual"
   },
   "source": [
    "### Creación de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-pickup",
   "metadata": {
    "id": "reduced-pickup"
   },
   "source": [
    "**Crear la variable \"captacion_corregido\" en donde si captacion es \"EXPRESS\", tome el valor \"Rápido\" y si no tome el valor \"Básico.**\n",
    "\n",
    "Se puede hacer con np.where, con .loc o con .map y un diccionario.\n",
    "\n",
    "**HACERLO SOBRE DF_MERGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-still",
   "metadata": {
    "id": "raising-still",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-substitute",
   "metadata": {
    "id": "regulation-substitute",
    "outputId": "4558083c-1521-4cca-f240-3facde375982",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "plain-jewelry",
   "metadata": {
    "id": "plain-jewelry"
   },
   "source": [
    "**Usando Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-space",
   "metadata": {
    "id": "compliant-space",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-seattle",
   "metadata": {
    "id": "alpha-seattle",
    "outputId": "942a6c9e-265d-47f8-ae43-e325f1a6b830",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "armed-longitude",
   "metadata": {
    "id": "armed-longitude"
   },
   "source": [
    "**Usando Replace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-caribbean",
   "metadata": {
    "id": "terminal-caribbean",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-lesbian",
   "metadata": {
    "id": "dated-lesbian",
    "outputId": "b4028496-7c42-40fd-bfd2-617f2749de12",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "progressive-botswana",
   "metadata": {
    "id": "progressive-botswana"
   },
   "source": [
    "**2) Crear la columna \"flag_predictor\" de la siguiente manera**:\n",
    "\n",
    "Si predictor > 800 entonces flag_predictor = \"Alto\";\n",
    "Si predictor es maor a 600 pero menor a 800 entonces flag_predictor = \"Medio\";\n",
    "Si predictor es menor o igual a 600 flag_predictor = \"Bajo\".\n",
    "\n",
    "**Tener cuidado con los nulos** Si predictor1_6 es nulo ponerle el valor \"Revisar\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-convergence",
   "metadata": {
    "id": "accompanied-convergence"
   },
   "source": [
    "**- Usando np.where**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-mountain",
   "metadata": {
    "id": "absolute-mountain",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-mouse",
   "metadata": {
    "id": "vocal-mouse",
    "outputId": "521f245d-f845-4faf-852e-09219df5f0ed",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "macro-drive",
   "metadata": {
    "id": "macro-drive"
   },
   "source": [
    "**- Usando If-else**\n",
    "\n",
    "Para esto usaremos lambda x, que aunque no este en las NB de teoria se suele utilizar para este tipo de cosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-default",
   "metadata": {
    "id": "periodic-default",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brief-arthritis",
   "metadata": {
    "id": "brief-arthritis"
   },
   "source": [
    "**- EXTRA: Usando cut**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-start",
   "metadata": {
    "id": "regular-start",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-helena",
   "metadata": {
    "id": "civilian-helena",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "801ea9dc",
   "metadata": {},
   "source": [
    "**EXTRA - Crear una columna que sea \"nueva_col\" la cual sea cada valor de la columna predictor 1_7 menos la resta del valor máximo de esa columna**.\n",
    "\n",
    "Ejemplo, si el valor maximo de la columna predictor1_7 es 100, y en la primer fila tenemos el valor 80, el valor de esa fila para la nueva columna seria (80-100) = -20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be76cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
